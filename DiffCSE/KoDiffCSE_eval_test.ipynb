{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x,y):\n",
    "  \"\"\" return euclidean distance between two lists \"\"\"\n",
    " \n",
    "  return math.sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    "\n",
    "def squared_sum(x):\n",
    "  \"\"\" return 3 rounded square rooted value \"\"\"\n",
    " \n",
    "  return round(math.sqrt(sum([a*a for a in x])),3)\n",
    "  \n",
    "def cos_similarity(x,y):\n",
    "  \"\"\" return cosine similarity between two lists \"\"\"\n",
    " \n",
    "  numerator = sum(a*b for a,b in zip(x,y))\n",
    "  denominator = squared_sum(x)*squared_sum(y)\n",
    "  return round(numerator/float(denominator),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor, device\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from typing import List, Dict, Tuple, Type, Union\n",
    "from kobert_tokenizer import KoBertTokenizer\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s', datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_dev = pd.read_csv(\"/home/keonwoo/anaconda3/envs/KoDiffCSE/data/ko_sts_dev.txt\")\n",
    "sts_test = pd.read_csv(\"/home/keonwoo/anaconda3/envs/KoDiffCSE/data/ko_sts_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffCSE(object):\n",
    "    \"\"\"\n",
    "    A class for embedding sentences, calculating similarities, and retriving sentences by DiffCSE. The code here is provided by SimCSE.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name_or_path: str, \n",
    "                device: str = None,\n",
    "                num_cells: int = 100,\n",
    "                num_cells_in_search: int = 10,\n",
    "                pooler = None):\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        # self.tokenizer = KoBertTokenizer.from_pretrained(model_name_or_path)\n",
    "        self.model = AutoModel.from_pretrained(model_name_or_path)\n",
    "        if device is None:\n",
    "            device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = device\n",
    "\n",
    "        self.index = None\n",
    "        self.is_faiss_index = False\n",
    "        self.num_cells = num_cells\n",
    "        self.num_cells_in_search = num_cells_in_search\n",
    "\n",
    "        if pooler is not None:\n",
    "            self.pooler = pooler\n",
    "        else:\n",
    "            logger.info(\"Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\")\n",
    "            self.pooler = \"cls_before_pooler\"\n",
    "    \n",
    "    def encode(self, sentence: Union[str, List[str]], \n",
    "                device: str = None, \n",
    "                return_numpy: bool = False,\n",
    "                normalize_to_unit: bool = True,\n",
    "                keepdim: bool = False,\n",
    "                batch_size: int = 64,\n",
    "                max_length: int = 128) -> Union[ndarray, Tensor]:\n",
    "\n",
    "        target_device = self.device if device is None else device\n",
    "        self.model = self.model.to(target_device)\n",
    "        \n",
    "        single_sentence = False\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = [sentence]\n",
    "            single_sentence = True\n",
    "\n",
    "        embedding_list = [] \n",
    "        with torch.no_grad():\n",
    "            total_batch = len(sentence) // batch_size + (1 if len(sentence) % batch_size > 0 else 0)\n",
    "            for batch_id in tqdm(range(total_batch)):\n",
    "                inputs = self.tokenizer(\n",
    "                    sentence[batch_id*batch_size:(batch_id+1)*batch_size], \n",
    "                    padding=True, \n",
    "                    truncation=True, \n",
    "                    max_length=max_length, \n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                inputs = {k: v.to(target_device) for k, v in inputs.items()}\n",
    "                outputs = self.model(**inputs, return_dict=True)\n",
    "                if self.pooler == \"cls\":\n",
    "                    embeddings = outputs.pooler_output\n",
    "                elif self.pooler == \"cls_before_pooler\":\n",
    "                    embeddings = outputs.last_hidden_state[:, 0]\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                if normalize_to_unit:\n",
    "                    embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)\n",
    "                embedding_list.append(embeddings.cpu())\n",
    "        embeddings = torch.cat(embedding_list, 0)\n",
    "        \n",
    "        if single_sentence and not keepdim:\n",
    "            embeddings = embeddings[0]\n",
    "        \n",
    "        if return_numpy and not isinstance(embeddings, ndarray):\n",
    "            return embeddings.numpy()\n",
    "        return embeddings\n",
    "    \n",
    "    def similarity(self, queries: Union[str, List[str]], \n",
    "                    keys: Union[str, List[str], ndarray], \n",
    "                    device: str = None) -> Union[float, ndarray]:\n",
    "        \n",
    "        query_vecs = self.encode(queries, device=device, return_numpy=True) # suppose N queries\n",
    "        \n",
    "        if not isinstance(keys, ndarray):\n",
    "            key_vecs = self.encode(keys, device=device, return_numpy=True) # suppose M keys\n",
    "        else:\n",
    "            key_vecs = keys\n",
    "\n",
    "        # check whether N == 1 or M == 1\n",
    "        single_query, single_key = len(query_vecs.shape) == 1, len(key_vecs.shape) == 1 \n",
    "        if single_query:\n",
    "            query_vecs = query_vecs.reshape(1, -1)\n",
    "        if single_key:\n",
    "            key_vecs = key_vecs.reshape(1, -1)\n",
    "        \n",
    "        # returns an N*M similarity array\n",
    "        similarities = cosine_similarity(query_vecs, key_vecs)\n",
    "        \n",
    "        if single_query:\n",
    "            similarities = similarities[0]\n",
    "            if single_key:\n",
    "                similarities = float(similarities[0])\n",
    "        \n",
    "        return similarities\n",
    "    \n",
    "    def build_index(self, sentences_or_file_path: Union[str, List[str]], \n",
    "                        use_faiss: bool = None,\n",
    "                        faiss_fast: bool = False,\n",
    "                        device: str = None,\n",
    "                        batch_size: int = 64):\n",
    "\n",
    "        if use_faiss is None or use_faiss:\n",
    "            try:\n",
    "                import faiss\n",
    "                assert hasattr(faiss, \"IndexFlatIP\")\n",
    "                use_faiss = True \n",
    "            except:\n",
    "                logger.warning(\"Fail to import faiss. If you want to use faiss, install faiss through PyPI. Now the program continues with brute force search.\")\n",
    "                use_faiss = False\n",
    "        \n",
    "        # if the input sentence is a string, we assume it's the path of file that stores various sentences\n",
    "        if isinstance(sentences_or_file_path, str):\n",
    "            sentences = []\n",
    "            with open(sentences_or_file_path, \"r\") as f:\n",
    "                logging.info(\"Loading sentences from %s ...\" % (sentences_or_file_path))\n",
    "                for line in tqdm(f):\n",
    "                    sentences.append(line.rstrip())\n",
    "            sentences_or_file_path = sentences\n",
    "        \n",
    "        logger.info(\"Encoding embeddings for sentences...\")\n",
    "        embeddings = self.encode(sentences_or_file_path, device=device, batch_size=batch_size, normalize_to_unit=True, return_numpy=True)\n",
    "\n",
    "        logger.info(\"Building index...\")\n",
    "        self.index = {\"sentences\": sentences_or_file_path}\n",
    "        \n",
    "        if use_faiss:\n",
    "            quantizer = faiss.IndexFlatIP(embeddings.shape[1])  \n",
    "            if faiss_fast:\n",
    "                index = faiss.IndexIVFFlat(quantizer, embeddings.shape[1], min(self.num_cells, len(sentences_or_file_path))) \n",
    "            else:\n",
    "                index = quantizer\n",
    "\n",
    "            if (self.device == \"cuda\" and device != \"cpu\") or device == \"cuda\":\n",
    "                if hasattr(faiss, \"StandardGpuResources\"):\n",
    "                    logger.info(\"Use GPU-version faiss\")\n",
    "                    res = faiss.StandardGpuResources()\n",
    "                    res.setTempMemory(20 * 1024 * 1024 * 1024)\n",
    "                    index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "                else:\n",
    "                    logger.info(\"Use CPU-version faiss\")\n",
    "            else: \n",
    "                logger.info(\"Use CPU-version faiss\")\n",
    "\n",
    "            if faiss_fast:            \n",
    "                index.train(embeddings.astype(np.float32))\n",
    "            index.add(embeddings.astype(np.float32))\n",
    "            index.nprobe = min(self.num_cells_in_search, len(sentences_or_file_path))\n",
    "            self.is_faiss_index = True\n",
    "        else:\n",
    "            index = embeddings\n",
    "            self.is_faiss_index = False\n",
    "        self.index[\"index\"] = index\n",
    "        logger.info(\"Finished\")\n",
    "    \n",
    "    def search(self, queries: Union[str, List[str]], \n",
    "                device: str = None, \n",
    "                threshold: float = 0,\n",
    "                top_k: int = 5) -> Union[List[Tuple[str, float]], List[List[Tuple[str, float]]]]:\n",
    "        \n",
    "        if not self.is_faiss_index:\n",
    "            if isinstance(queries, list):\n",
    "                combined_results = []\n",
    "                for query in queries:\n",
    "                    results = self.search(query, device)\n",
    "                    combined_results.append(results)\n",
    "                return combined_results\n",
    "            \n",
    "            similarities = self.similarity(queries, self.index[\"index\"]).tolist()\n",
    "            id_and_score = []\n",
    "            for i, s in enumerate(similarities):\n",
    "                if s >= threshold:\n",
    "                    id_and_score.append((i, s))\n",
    "            id_and_score = sorted(id_and_score, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "            results = [(self.index[\"sentences\"][idx], score) for idx, score in id_and_score]\n",
    "            return results\n",
    "        else:\n",
    "            query_vecs = self.encode(queries, device=device, normalize_to_unit=True, keepdim=True, return_numpy=True)\n",
    "\n",
    "            distance, idx = self.index[\"index\"].search(query_vecs.astype(np.float32), top_k)\n",
    "            \n",
    "            def pack_single_result(dist, idx):\n",
    "                results = [(self.index[\"sentences\"][i], s) for i, s in zip(idx, dist) if s >= threshold]\n",
    "                return results\n",
    "            \n",
    "            if isinstance(queries, list):\n",
    "                combined_results = []\n",
    "                for i in range(len(queries)):\n",
    "                    results = pack_single_result(distance[i], idx[i])\n",
    "                    combined_results.append(results)\n",
    "                return combined_results\n",
    "            else:\n",
    "                return pack_single_result(distance[0], idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(eval_dataset,model):\n",
    "    sen_emb1 = model.encode(eval_dataset['sentence1'].tolist())\n",
    "    sen_emb2 = model.encode(eval_dataset['sentence2'].tolist())\n",
    "    labels = eval_dataset['score']\n",
    "\n",
    "    cosine_scores = 1 - (paired_cosine_distances(sen_emb1, sen_emb2))\n",
    "    manhattan_distances = -paired_manhattan_distances(sen_emb1, sen_emb2)\n",
    "    euclidean_distances = -paired_euclidean_distances(sen_emb1, sen_emb2)\n",
    "    dot_products = [np.dot(emb1, emb2) for emb1, emb2 in zip(sen_emb1, sen_emb2)]\n",
    "    \n",
    "    eval_pearson_cosine, _ = pearsonr(labels, cosine_scores)\n",
    "    eval_spearman_cosine, _ = spearmanr(labels, cosine_scores)\n",
    "\n",
    "    eval_pearson_manhattan, _ = pearsonr(labels, manhattan_distances)\n",
    "    eval_spearman_manhattan, _ = spearmanr(labels, manhattan_distances)\n",
    "\n",
    "    eval_pearson_euclidean, _ = pearsonr(labels, euclidean_distances)\n",
    "    eval_spearman_euclidean, _ = spearmanr(labels, euclidean_distances)\n",
    "\n",
    "    eval_pearson_dot, _ = pearsonr(labels, dot_products)\n",
    "    eval_spearman_dot, _ = spearmanr(labels, dot_products)\n",
    "\n",
    "    score = {'eval_pearson_cosine': eval_pearson_cosine,\n",
    "            'eval_spearman_cosine': eval_spearman_cosine,\n",
    "            'eval_pearson_manhattan': eval_pearson_manhattan,\n",
    "            'eval_spearman_manhattan': eval_spearman_manhattan,\n",
    "            'eval_pearson_euclidean': eval_pearson_euclidean,\n",
    "            'eval_spearman_euclidean': eval_spearman_euclidean,\n",
    "            'eval_pearson_dot': eval_pearson_dot,\n",
    "            'eval_spearman_dot': eval_spearman_dot}\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0720/epoch=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0720_epoch=1 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/21/2022 18:51:39 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0720_epoch=1\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.56it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7430483153702674,\n",
       " 'eval_spearman_cosine': 0.7415490325180422,\n",
       " 'eval_pearson_manhattan': 0.7334779689669992,\n",
       " 'eval_spearman_manhattan': 0.7416093893020635,\n",
       " 'eval_pearson_euclidean': 0.7333004017195163,\n",
       " 'eval_spearman_euclidean': 0.7415480872721462,\n",
       " 'eval_pearson_dot': 0.7430483193293904,\n",
       " 'eval_spearman_dot': 0.7415495188249112}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 21.85it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.6789423949638527,\n",
       " 'eval_spearman_cosine': 0.6689631112979975,\n",
       " 'eval_pearson_manhattan': 0.6691956475211638,\n",
       " 'eval_spearman_manhattan': 0.66911377956273,\n",
       " 'eval_pearson_euclidean': 0.6686868295838538,\n",
       " 'eval_spearman_euclidean': 0.668962482106489,\n",
       " 'eval_pearson_dot': 0.6789423604048723,\n",
       " 'eval_spearman_dot': 0.6689578314366862}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0721/epoch=1_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=1_update and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/21/2022 18:43:09 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=1_update\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.72it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.662757380420375,\n",
       " 'eval_spearman_cosine': 0.6641554724076045,\n",
       " 'eval_pearson_manhattan': 0.6569087920857435,\n",
       " 'eval_spearman_manhattan': 0.6665474061347986,\n",
       " 'eval_pearson_euclidean': 0.6542220340677666,\n",
       " 'eval_spearman_euclidean': 0.6641554740588386,\n",
       " 'eval_pearson_dot': 0.662757394704638,\n",
       " 'eval_spearman_dot': 0.6641546651426425}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 21.89it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.5916246647737429,\n",
       " 'eval_spearman_cosine': 0.5756435421929641,\n",
       " 'eval_pearson_manhattan': 0.5778638048876472,\n",
       " 'eval_spearman_manhattan': 0.5764579773386374,\n",
       " 'eval_pearson_euclidean': 0.5769955818280884,\n",
       " 'eval_spearman_euclidean': 0.5756429198787706,\n",
       " 'eval_pearson_dot': 0.5916246496003235,\n",
       " 'eval_spearman_dot': 0.5756421480932179}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0721/epoch=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=2 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/21/2022 18:43:55 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=2\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.72it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7429097011937542,\n",
       " 'eval_spearman_cosine': 0.7426633860985158,\n",
       " 'eval_pearson_manhattan': 0.7331639057210683,\n",
       " 'eval_spearman_manhattan': 0.7423990207626731,\n",
       " 'eval_pearson_euclidean': 0.7334587848287031,\n",
       " 'eval_spearman_euclidean': 0.7426628686388035,\n",
       " 'eval_pearson_dot': 0.7429097086974977,\n",
       " 'eval_spearman_dot': 0.7426633098511968}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 21.89it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.6816542228074193,\n",
       " 'eval_spearman_cosine': 0.6753138250845714,\n",
       " 'eval_pearson_manhattan': 0.6715845931475771,\n",
       " 'eval_spearman_manhattan': 0.6745285209567878,\n",
       " 'eval_pearson_euclidean': 0.6714984469001893,\n",
       " 'eval_spearman_euclidean': 0.6753139993475267,\n",
       " 'eval_pearson_dot': 0.6816542522447457,\n",
       " 'eval_spearman_dot': 0.6753131747006083}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0721/epoch=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=3 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/21/2022 18:44:47 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=3\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.73it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7449418939470757,\n",
       " 'eval_spearman_cosine': 0.7450532388568598,\n",
       " 'eval_pearson_manhattan': 0.7352325024479718,\n",
       " 'eval_spearman_manhattan': 0.744819342671332,\n",
       " 'eval_pearson_euclidean': 0.7355379483476462,\n",
       " 'eval_spearman_euclidean': 0.745052981579705,\n",
       " 'eval_pearson_dot': 0.7449418548077157,\n",
       " 'eval_spearman_dot': 0.7450557130956711}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 21.98it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.682553044782682,\n",
       " 'eval_spearman_cosine': 0.6762187768957946,\n",
       " 'eval_pearson_manhattan': 0.6717086608629301,\n",
       " 'eval_spearman_manhattan': 0.6758890202105615,\n",
       " 'eval_pearson_euclidean': 0.671870973444449,\n",
       " 'eval_spearman_euclidean': 0.6762181471695697,\n",
       " 'eval_pearson_dot': 0.6825530703190852,\n",
       " 'eval_spearman_dot': 0.6762195327624885}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0721/epoch=3_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=5 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/26/2022 15:26:33 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=5\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 10.63it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 11.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7537775419741063,\n",
       " 'eval_spearman_cosine': 0.7522780040723923,\n",
       " 'eval_pearson_manhattan': 0.7422700944976672,\n",
       " 'eval_spearman_manhattan': 0.7511530251300458,\n",
       " 'eval_pearson_euclidean': 0.7433892370711733,\n",
       " 'eval_spearman_euclidean': 0.7522770526196226,\n",
       " 'eval_pearson_dot': 0.753777531339438,\n",
       " 'eval_spearman_dot': 0.7522808528224674}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 12.48it/s]\n",
      "100%|██████████| 22/22 [00:02<00:00, 10.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.6936895655983226,\n",
       " 'eval_spearman_cosine': 0.6833076355803068,\n",
       " 'eval_pearson_manhattan': 0.6804828262310914,\n",
       " 'eval_spearman_manhattan': 0.68206494912713,\n",
       " 'eval_pearson_euclidean': 0.6813340804473689,\n",
       " 'eval_spearman_euclidean': 0.6833084982377086,\n",
       " 'eval_pearson_dot': 0.6936895974779715,\n",
       " 'eval_spearman_dot': 0.6833125891721886}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ko_output_model_0721_epoch=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=5 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/22/2022 10:38:32 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0721_epoch=5\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.71it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7537775419741063,\n",
       " 'eval_spearman_cosine': 0.7522780040723923,\n",
       " 'eval_pearson_manhattan': 0.7422700944976672,\n",
       " 'eval_spearman_manhattan': 0.7511530251300458,\n",
       " 'eval_pearson_euclidean': 0.7433892370711733,\n",
       " 'eval_spearman_euclidean': 0.7522770526196226,\n",
       " 'eval_pearson_dot': 0.753777531339438,\n",
       " 'eval_spearman_dot': 0.7522808528224674}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 21.88it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.6936895655983226,\n",
       " 'eval_spearman_cosine': 0.6833076355803068,\n",
       " 'eval_pearson_manhattan': 0.6804828262310914,\n",
       " 'eval_spearman_manhattan': 0.68206494912713,\n",
       " 'eval_pearson_euclidean': 0.6813340804473689,\n",
       " 'eval_spearman_euclidean': 0.6833084982377086,\n",
       " 'eval_pearson_dot': 0.6936895974779715,\n",
       " 'eval_spearman_dot': 0.6833125891721886}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ko_output_model_0722_epoch=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0722_epoch=3\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.70it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7496809739171452,\n",
       " 'eval_spearman_cosine': 0.7498079530787528,\n",
       " 'eval_pearson_manhattan': 0.740212708489065,\n",
       " 'eval_spearman_manhattan': 0.7490060256935015,\n",
       " 'eval_pearson_euclidean': 0.7409064642188012,\n",
       " 'eval_spearman_euclidean': 0.7498067407181096,\n",
       " 'eval_pearson_dot': 0.7496809759863061,\n",
       " 'eval_spearman_dot': 0.7498089403312816}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 21.89it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.6889303965449269,\n",
       " 'eval_spearman_cosine': 0.6819790313592456,\n",
       " 'eval_pearson_manhattan': 0.6792995190430124,\n",
       " 'eval_spearman_manhattan': 0.6819558765224221,\n",
       " 'eval_pearson_euclidean': 0.6791308900885948,\n",
       " 'eval_spearman_euclidean': 0.6819778516592317,\n",
       " 'eval_pearson_dot': 0.6889303110917411,\n",
       " 'eval_spearman_dot': 0.6819811436246029}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0722_epoch=3 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/24/2022 17:12:14 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0722_epoch=3\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.73it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7497982564224046,\n",
       " 'eval_spearman_cosine': 0.7498380643959762,\n",
       " 'eval_pearson_manhattan': 0.7402435924557833,\n",
       " 'eval_spearman_manhattan': 0.7497757682262272,\n",
       " 'eval_pearson_euclidean': 0.7404489069959012,\n",
       " 'eval_spearman_euclidean': 0.7498378084675342,\n",
       " 'eval_pearson_dot': 0.7497983009103533,\n",
       " 'eval_spearman_dot': 0.7498411844108553}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 21.95it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.6890170554605594,\n",
       " 'eval_spearman_cosine': 0.6823636423047701,\n",
       " 'eval_pearson_manhattan': 0.6784021278191614,\n",
       " 'eval_spearman_manhattan': 0.6822042786868168,\n",
       " 'eval_pearson_euclidean': 0.6781986054362115,\n",
       " 'eval_spearman_euclidean': 0.6823627262150469,\n",
       " 'eval_pearson_dot': 0.6890170336613468,\n",
       " 'eval_spearman_dot': 0.6823622649592354}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0725_epoch=3_wiki and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/27/2022 13:08:22 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0725_epoch=3_wiki\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.58it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7423878931147392,\n",
       " 'eval_spearman_cosine': 0.7478232245078454,\n",
       " 'eval_pearson_manhattan': 0.7440739440823739,\n",
       " 'eval_spearman_manhattan': 0.747558367245619,\n",
       " 'eval_pearson_euclidean': 0.7442273147515874,\n",
       " 'eval_spearman_euclidean': 0.7478229657560735,\n",
       " 'eval_pearson_dot': 0.7423879241012167,\n",
       " 'eval_spearman_dot': 0.7478231529370889}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 21.92it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.6885252617917498,\n",
       " 'eval_spearman_cosine': 0.6901729124525737,\n",
       " 'eval_pearson_manhattan': 0.6859499901719317,\n",
       " 'eval_spearman_manhattan': 0.6891210197478684,\n",
       " 'eval_pearson_euclidean': 0.6861915056026157,\n",
       " 'eval_spearman_euclidean': 0.6901720180499071,\n",
       " 'eval_pearson_dot': 0.6885252278955448,\n",
       " 'eval_spearman_dot': 0.6901720203556381}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0726_epoch=2_wiki and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/26/2022 15:44:50 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0726_epoch=2_wiki\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.63it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7355747969457602,\n",
       " 'eval_spearman_cosine': 0.7390648904711767,\n",
       " 'eval_pearson_manhattan': 0.7326426533278265,\n",
       " 'eval_spearman_manhattan': 0.7381511393261372,\n",
       " 'eval_pearson_euclidean': 0.7332278939062458,\n",
       " 'eval_spearman_euclidean': 0.7390643183949986,\n",
       " 'eval_pearson_dot': 0.7355747733729483,\n",
       " 'eval_spearman_dot': 0.7390650220120545}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 21.85it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.6884438642495199,\n",
       " 'eval_spearman_cosine': 0.6853356579347044,\n",
       " 'eval_pearson_manhattan': 0.6796456195169459,\n",
       " 'eval_spearman_manhattan': 0.6850308792888224,\n",
       " 'eval_pearson_euclidean': 0.6797312292188201,\n",
       " 'eval_spearman_euclidean': 0.6853349291175604,\n",
       " 'eval_pearson_dot': 0.6884438761847315,\n",
       " 'eval_spearman_dot': 0.6853380693996083}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0726_epoch=3_wiki_roberta and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/28/2022 17:15:08 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/ko_output_model_0726_epoch=3_wiki_roberta\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 21.54it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 23.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8687910643488711,\n",
       " 'eval_spearman_cosine': 0.8716889054665014,\n",
       " 'eval_pearson_manhattan': 0.865198609618478,\n",
       " 'eval_spearman_manhattan': 0.8714871023375671,\n",
       " 'eval_pearson_euclidean': 0.8650005637173033,\n",
       " 'eval_spearman_euclidean': 0.8716889445925671,\n",
       " 'eval_pearson_dot': 0.8687910668719111,\n",
       " 'eval_spearman_dot': 0.8716884249150619}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 26.09it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 27.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8378953046255182,\n",
       " 'eval_spearman_cosine': 0.8418862800933891,\n",
       " 'eval_pearson_manhattan': 0.8405632262518306,\n",
       " 'eval_spearman_manhattan': 0.8420296218357668,\n",
       " 'eval_pearson_euclidean': 0.8406600675926741,\n",
       " 'eval_spearman_euclidean': 0.8418890852259043,\n",
       " 'eval_pearson_dot': 0.8378953029110046,\n",
       " 'eval_spearman_dot': 0.8418864059664883}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/klue_roberta_wiki_nli and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/28/2022 15:10:58 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/klue_roberta_wiki_nli\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 20.39it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 21.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.81116548985272,\n",
       " 'eval_spearman_cosine': 0.8070159995898994,\n",
       " 'eval_pearson_manhattan': 0.8039373824062716,\n",
       " 'eval_spearman_manhattan': 0.8069157506661292,\n",
       " 'eval_pearson_euclidean': 0.8041587886543301,\n",
       " 'eval_spearman_euclidean': 0.8070160873304586,\n",
       " 'eval_pearson_dot': 0.8111654768822352,\n",
       " 'eval_spearman_dot': 0.8070161219556101}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 24.18it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 24.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.7672836498111705,\n",
       " 'eval_spearman_cosine': 0.7530479775086246,\n",
       " 'eval_pearson_manhattan': 0.7652537526424827,\n",
       " 'eval_spearman_manhattan': 0.7521709432779005,\n",
       " 'eval_pearson_euclidean': 0.7661168415898592,\n",
       " 'eval_spearman_euclidean': 0.7530515342250392,\n",
       " 'eval_pearson_dot': 0.7672836503851974,\n",
       " 'eval_spearman_dot': 0.7530506724231747}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/28/2022 16:51:24 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 21.08it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 22.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8677051357322766,\n",
       " 'eval_spearman_cosine': 0.8703762435501177,\n",
       " 'eval_pearson_manhattan': 0.8637662440953195,\n",
       " 'eval_spearman_manhattan': 0.8705912673676367,\n",
       " 'eval_pearson_euclidean': 0.8634209675720484,\n",
       " 'eval_spearman_euclidean': 0.8703764408621967,\n",
       " 'eval_pearson_dot': 0.8677051350098797,\n",
       " 'eval_spearman_dot': 0.8703760251444351}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 25.99it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 26.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8354898438099596,\n",
       " 'eval_spearman_cosine': 0.8389973096191164,\n",
       " 'eval_pearson_manhattan': 0.8373701973555356,\n",
       " 'eval_spearman_manhattan': 0.8391687376836482,\n",
       " 'eval_pearson_euclidean': 0.8371371947826659,\n",
       " 'eval_spearman_euclidean': 0.8390001149645382,\n",
       " 'eval_pearson_dot': 0.8354898489586187,\n",
       " 'eval_spearman_dot': 0.8389966127531397}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/29/2022 11:47:46 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 20.99it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 23.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8705672441523,\n",
       " 'eval_spearman_cosine': 0.8731524742242264,\n",
       " 'eval_pearson_manhattan': 0.8667139824831696,\n",
       " 'eval_spearman_manhattan': 0.8731835296107339,\n",
       " 'eval_pearson_euclidean': 0.8665520167926218,\n",
       " 'eval_spearman_euclidean': 0.8731523597859316,\n",
       " 'eval_pearson_dot': 0.8705672400657357,\n",
       " 'eval_spearman_dot': 0.8731528690272887}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 25.44it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 26.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8396358894503797,\n",
       " 'eval_spearman_cosine': 0.8445370593154237,\n",
       " 'eval_pearson_manhattan': 0.8422651929042944,\n",
       " 'eval_spearman_manhattan': 0.8445982693912436,\n",
       " 'eval_pearson_euclidean': 0.8422348443452508,\n",
       " 'eval_spearman_euclidean': 0.8445401280784124,\n",
       " 'eval_pearson_dot': 0.8396358914893068,\n",
       " 'eval_spearman_dot': 0.8445356720337045}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_7e-7 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/31/2022 20:39:06 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_7e-7\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 20.61it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 23.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8703719225199198,\n",
       " 'eval_spearman_cosine': 0.8728109872851335,\n",
       " 'eval_pearson_manhattan': 0.8662857455556076,\n",
       " 'eval_spearman_manhattan': 0.8728083176251981,\n",
       " 'eval_pearson_euclidean': 0.8661013996262362,\n",
       " 'eval_spearman_euclidean': 0.8728110737701502,\n",
       " 'eval_pearson_dot': 0.8703719178834881,\n",
       " 'eval_spearman_dot': 0.87281079273135}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 25.80it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 27.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8393259454132976,\n",
       " 'eval_spearman_cosine': 0.8441974181976699,\n",
       " 'eval_pearson_manhattan': 0.8419134079057237,\n",
       " 'eval_spearman_manhattan': 0.8442122392961918,\n",
       " 'eval_pearson_euclidean': 0.841858186604366,\n",
       " 'eval_spearman_euclidean': 0.8442002231598625,\n",
       " 'eval_pearson_dot': 0.8393259492453873,\n",
       " 'eval_spearman_dot': 0.8441973863636499}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_9e-7 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/31/2022 20:40:15 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_9e-7\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 21.21it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 22.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8704430788641979,\n",
       " 'eval_spearman_cosine': 0.8730103762576663,\n",
       " 'eval_pearson_manhattan': 0.8665732188156173,\n",
       " 'eval_spearman_manhattan': 0.8730911458636692,\n",
       " 'eval_pearson_euclidean': 0.8663845005636351,\n",
       " 'eval_spearman_euclidean': 0.8730106774930061,\n",
       " 'eval_pearson_dot': 0.8704430749079863,\n",
       " 'eval_spearman_dot': 0.8730103217003322}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 26.34it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 27.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8393245922075555,\n",
       " 'eval_spearman_cosine': 0.8441979956025604,\n",
       " 'eval_pearson_manhattan': 0.8419665061597279,\n",
       " 'eval_spearman_manhattan': 0.844372613443418,\n",
       " 'eval_pearson_euclidean': 0.841925903300984,\n",
       " 'eval_spearman_euclidean': 0.844200474484541,\n",
       " 'eval_pearson_dot': 0.8393245878975801,\n",
       " 'eval_spearman_dot': 0.8441987306730684}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_5e-7 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/31/2022 20:40:46 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_5e-7\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 21.07it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 23.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8700885518135814,\n",
       " 'eval_spearman_cosine': 0.8725837960783911,\n",
       " 'eval_pearson_manhattan': 0.865985355644485,\n",
       " 'eval_spearman_manhattan': 0.8726118291292423,\n",
       " 'eval_pearson_euclidean': 0.8657674603393741,\n",
       " 'eval_spearman_euclidean': 0.8725844090204875,\n",
       " 'eval_pearson_dot': 0.8700885523604038,\n",
       " 'eval_spearman_dot': 0.8725841077774202}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 25.90it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 26.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8389062028665961,\n",
       " 'eval_spearman_cosine': 0.8436164118072936,\n",
       " 'eval_pearson_manhattan': 0.8412994493413722,\n",
       " 'eval_spearman_manhattan': 0.8435513650948918,\n",
       " 'eval_pearson_euclidean': 0.8412178273116202,\n",
       " 'eval_spearman_euclidean': 0.8436192168123077,\n",
       " 'eval_pearson_dot': 0.8389062015868869,\n",
       " 'eval_spearman_dot': 0.8436176915069955}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_1e-7 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/31/2022 20:41:18 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_1e-7\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 21.17it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 22.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8703765260274898,\n",
       " 'eval_spearman_cosine': 0.8729237864028652,\n",
       " 'eval_pearson_manhattan': 0.8663161809252254,\n",
       " 'eval_spearman_manhattan': 0.8730032953029576,\n",
       " 'eval_pearson_euclidean': 0.8661111072564047,\n",
       " 'eval_spearman_euclidean': 0.8729241421971914,\n",
       " 'eval_pearson_dot': 0.8703765329273702,\n",
       " 'eval_spearman_dot': 0.87292380995555}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 26.08it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 26.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.839479303863836,\n",
       " 'eval_spearman_cosine': 0.8440946263966163,\n",
       " 'eval_pearson_manhattan': 0.8419249592818503,\n",
       " 'eval_spearman_manhattan': 0.8440635670952641,\n",
       " 'eval_pearson_euclidean': 0.8418341181072792,\n",
       " 'eval_spearman_euclidean': 0.8440974313663845,\n",
       " 'eval_pearson_dot': 0.839479306331645,\n",
       " 'eval_spearman_dot': 0.8440959887698793}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_7e-8 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/31/2022 20:41:48 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_7e-8\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 21.29it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 22.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8704265489944512,\n",
       " 'eval_spearman_cosine': 0.873031324174672,\n",
       " 'eval_pearson_manhattan': 0.866514516247571,\n",
       " 'eval_spearman_manhattan': 0.8729967859876443,\n",
       " 'eval_pearson_euclidean': 0.8663436886647545,\n",
       " 'eval_spearman_euclidean': 0.8730314106554843,\n",
       " 'eval_pearson_dot': 0.8704265425238364,\n",
       " 'eval_spearman_dot': 0.8730311992332854}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 26.13it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 26.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8396686993720296,\n",
       " 'eval_spearman_cosine': 0.8442649425070043,\n",
       " 'eval_pearson_manhattan': 0.8421512399138709,\n",
       " 'eval_spearman_manhattan': 0.8442785396188311,\n",
       " 'eval_pearson_euclidean': 0.8420734838543887,\n",
       " 'eval_spearman_euclidean': 0.844268009345378,\n",
       " 'eval_pearson_dot': 0.8396687038136059,\n",
       " 'eval_spearman_dot': 0.8442652043881809}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_1e-6_0731 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "08/01/2022 16:07:33 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/sroberta_change_lr_1e-6_0731\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 19.61it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 22.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8703825925377942,\n",
       " 'eval_spearman_cosine': 0.8729544023259009,\n",
       " 'eval_pearson_manhattan': 0.8665877997685989,\n",
       " 'eval_spearman_manhattan': 0.8730924966068773,\n",
       " 'eval_pearson_euclidean': 0.8663983282647466,\n",
       " 'eval_spearman_euclidean': 0.8729550748150902,\n",
       " 'eval_pearson_dot': 0.870382585703337,\n",
       " 'eval_spearman_dot': 0.872954207770749}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 25.79it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 26.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8392317814416363,\n",
       " 'eval_spearman_cosine': 0.8442386998277233,\n",
       " 'eval_pearson_manhattan': 0.842104208319224,\n",
       " 'eval_spearman_manhattan': 0.8441231587128242,\n",
       " 'eval_pearson_euclidean': 0.842034212732687,\n",
       " 'eval_spearman_euclidean': 0.8442417632094645,\n",
       " 'eval_pearson_dot': 0.8392317796629851,\n",
       " 'eval_spearman_dot': 0.8442394917029973}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/keonwoo/anaconda3/envs/KoDiffCSE/last_training_0802 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "08/02/2022 17:04:33 - INFO - __main__ -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/last_training_0802\"\n",
    "diffcse = DiffCSE(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 12.13it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 12.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8701157612651806,\n",
       " 'eval_spearman_cosine': 0.8728667472958714,\n",
       " 'eval_pearson_manhattan': 0.8665277694786487,\n",
       " 'eval_spearman_manhattan': 0.8729877684625479,\n",
       " 'eval_pearson_euclidean': 0.8662967386974056,\n",
       " 'eval_spearman_euclidean': 0.8728673652290121,\n",
       " 'eval_pearson_dot': 0.8701157605137709,\n",
       " 'eval_spearman_dot': 0.872866518239194}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(sts_dev, diffcse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 14.28it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 16.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_pearson_cosine': 0.8392139146784754,\n",
       " 'eval_spearman_cosine': 0.8442226659539233,\n",
       " 'eval_pearson_manhattan': 0.8421124381662313,\n",
       " 'eval_spearman_manhattan': 0.844189450784655,\n",
       " 'eval_pearson_euclidean': 0.8420537574882557,\n",
       " 'eval_spearman_euclidean': 0.8442252090330523,\n",
       " 'eval_pearson_dot': 0.8392139237100509,\n",
       " 'eval_spearman_dot': 0.8442242373481732}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluation(sts_test, diffcse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualititive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentences = ['한 남자가 음식을 먹는다.',\n",
    "              '한 남자가 빵 한 조각을 먹는다.',\n",
    "              '그 여자가 아이를 돌본다.',\n",
    "              '한 남자가 말을 탄다.',\n",
    "              '한 여자가 바이올린을 연주한다.',\n",
    "              '두 남자가 수레를 숲 속으로 밀었다.',\n",
    "              '한 남자가 담으로 싸인 땅에서 백마를 타고 있다.',\n",
    "              '원숭이 한 마리가 드럼을 연주한다.',\n",
    "              '치타 한 마리가 먹이 뒤에서 달리고 있다.']\n",
    "\n",
    "example_queries = ['한 남자가 파스타를 먹는다.',\n",
    "               '고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.',\n",
    "               '치타가 들판을 가로 질러 먹이를 쫓는다.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 75.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.08it/s]\n",
      "07/27/2022 13:08:37 - INFO - __main__ -   Encoding embeddings for sentences...\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.10it/s]\n",
      "07/27/2022 13:08:37 - INFO - __main__ -   Building index...\n",
      "07/27/2022 13:08:37 - INFO - __main__ -   Finished\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.70it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========Calculate cosine similarities between queries and sentences============\n",
      "\n",
      "\n",
      "=========Naive brute force search============\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 79.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval results for query: 한 남자가 파스타를 먹는다.\n",
      "    한 남자가 음식을 먹는다.  (cosine similarity: 0.5752)\n",
      "    한 남자가 빵 한 조각을 먹는다.  (cosine similarity: 0.5028)\n",
      "    치타 한 마리가 먹이 뒤에서 달리고 있다.  (cosine similarity: 0.1983)\n",
      "    한 여자가 바이올린을 연주한다.  (cosine similarity: 0.1840)\n",
      "    한 남자가 담으로 싸인 땅에서 백마를 타고 있다.  (cosine similarity: 0.1567)\n",
      "\n",
      "Retrieval results for query: 고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.\n",
      "    원숭이 한 마리가 드럼을 연주한다.  (cosine similarity: 0.7175)\n",
      "    한 여자가 바이올린을 연주한다.  (cosine similarity: 0.3894)\n",
      "    한 남자가 담으로 싸인 땅에서 백마를 타고 있다.  (cosine similarity: 0.3440)\n",
      "    치타 한 마리가 먹이 뒤에서 달리고 있다.  (cosine similarity: 0.3329)\n",
      "    한 남자가 음식을 먹는다.  (cosine similarity: 0.2224)\n",
      "\n",
      "Retrieval results for query: 치타가 들판을 가로 질러 먹이를 쫓는다.\n",
      "    치타 한 마리가 먹이 뒤에서 달리고 있다.  (cosine similarity: 0.8224)\n",
      "    원숭이 한 마리가 드럼을 연주한다.  (cosine similarity: 0.3260)\n",
      "    한 남자가 담으로 싸인 땅에서 백마를 타고 있다.  (cosine similarity: 0.2750)\n",
      "    두 남자가 수레를 숲 속으로 밀었다.  (cosine similarity: 0.2340)\n",
      "    한 남자가 음식을 먹는다.  (cosine similarity: 0.2312)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=========Calculate cosine similarities between queries and sentences============\\n\")\n",
    "similarities = diffcse.similarity(example_queries, example_sentences)\n",
    "# print(similarities)\n",
    "print(\"\\n=========Naive brute force search============\\n\")\n",
    "diffcse.build_index(example_sentences, use_faiss=False)\n",
    "results = diffcse.search(example_queries)\n",
    "for i, result in enumerate(results):\n",
    "    print(\"Retrieval results for query: {}\".format(example_queries[i]))\n",
    "    for sentence, score in result:\n",
    "        print(\"    {}  (cosine similarity: {:.4f})\".format(sentence, score))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/27/2022 13:06:51 - WARNING - __main__ -   Fail to import faiss. If you want to use faiss, install faiss through PyPI. Now the program continues with brute force search.\n",
      "07/27/2022 13:06:51 - INFO - __main__ -   Encoding embeddings for sentences...\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.96it/s]\n",
      "07/27/2022 13:06:51 - INFO - __main__ -   Building index...\n",
      "07/27/2022 13:06:51 - INFO - __main__ -   Finished\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========Search with Faiss backend============\n",
      "\n",
      "Retrieval results for query: 한 남자가 파스타를 먹는다.\n",
      "\n",
      "Retrieval results for query: 고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.\n",
      "    원숭이 한 마리가 드럼을 연주한다.  (cosine similarity: 0.7175)\n",
      "\n",
      "Retrieval results for query: 치타가 들판을 가로 질러 먹이를 쫓는다.\n",
      "    치타 한 마리가 먹이 뒤에서 달리고 있다.  (cosine similarity: 0.8224)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=========Search with Faiss backend============\\n\")\n",
    "diffcse.build_index(example_sentences, use_faiss=True)\n",
    "results = diffcse.search(example_queries)\n",
    "for i, result in enumerate(results):\n",
    "    print(\"Retrieval results for query: {}\".format(example_queries[i]))\n",
    "    for sentence, score in result:\n",
    "        print(\"    {}  (cosine similarity: {:.4f})\".format(sentence, score))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class contentDataset(Dataset):\n",
    "    def __init__(self, file, tok, max_len, pad_index=None):\n",
    "        super().__init__()\n",
    "        self.tok =tok\n",
    "        self.max_len = max_len\n",
    "        self.content = pd.read_csv(file)\n",
    "        self.len = self.content.shape[0]\n",
    "        self.pad_index = self.tok.pad_token\n",
    "    \n",
    "    def add_padding_data(self, inputs, max_len):\n",
    "        if len(inputs) < max_len:\n",
    "            # pad = np.array([self.pad_index] * (max_len - len(inputs)))\n",
    "            pad = np.array([0] * (max_len - len(inputs)))\n",
    "            inputs = np.concatenate([inputs, pad])\n",
    "            return inputs\n",
    "        else:\n",
    "            inputs = inputs[:max_len]\n",
    "            return inputs\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        instance = self.content.iloc[idx]\n",
    "        # text = \"[CLS]\" + instance['content'] + \"[SEP]\"\n",
    "        text_1 = instance['sentence1']\n",
    "        text_2 = instance['sentence2']\n",
    "\n",
    "        text_1_input_ids = self.tok.encode(text_1)\n",
    "        text_2_input_ids = self.tok.encode(text_2)\n",
    "        \n",
    "        text_1_input_ids = self.add_padding_data(text_1_input_ids, max_len=self.max_len)\n",
    "        text_2_input_ids = self.add_padding_data(text_2_input_ids, max_len=self.max_len)\n",
    "\n",
    "        label_ids = instance['score']\n",
    "        # encoder_attention_mask = input_ids.ne(0).float()\n",
    "        return {\"text1_encoder_input_ids\" : np.array(text_1_input_ids, dtype=np.int_),\n",
    "                \"text2_encoder_input_ids\" : np.array(text_2_input_ids, dtype=np.int_),\n",
    "                \"score\" : np.array(label_ids,dtype=np.int_)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert_tokenizer import KoBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\n",
    "file_path = \"/home/keonwoo/anaconda3/envs/KoDiffCSE/data/ko_sts_dev.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_setup = contentDataset(file = file_path, tok = tokenizer, max_len = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(valid_setup, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text1_encoder_input_ids': tensor([[   2, 3139, 6213,  ...,    0,    0,    0],\n",
      "        [   2, 3233, 6804,  ...,    0,    0,    0],\n",
      "        [   2, 4955, 1423,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2, 4955, 1423,  ...,    0,    0,    0],\n",
      "        [   2, 1185, 3318,  ...,    0,    0,    0],\n",
      "        [   2, 4955,  517,  ...,    0,    0,    0]]), 'text2_encoder_input_ids': tensor([[   2, 3139, 6213,  ...,    0,    0,    0],\n",
      "        [   2, 3121, 5330,  ...,    0,    0,    0],\n",
      "        [   2, 1423, 5330,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2, 4955, 3318,  ...,    0,    0,    0],\n",
      "        [   2, 1423, 5330,  ...,    0,    0,    0],\n",
      "        [   2, 4955,  517,  ...,    0,    0,    0]]), 'score': tensor([5, 4, 5, 2, 2, 2, 5, 2, 3, 5, 3, 1, 5, 5, 4, 0, 2, 5, 4, 0, 3, 1, 3, 2,\n",
      "        1, 1, 4, 3, 1, 0, 2, 5])}\n",
      "\n",
      "\n",
      "{'text1_encoder_input_ids': tensor([[   2, 3139, 6213,  ...,    0,    0,    0],\n",
      "        [   2, 3233, 6804,  ...,    0,    0,    0],\n",
      "        [   2, 4955, 1423,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2, 4955, 1423,  ...,    0,    0,    0],\n",
      "        [   2, 1185, 3318,  ...,    0,    0,    0],\n",
      "        [   2, 4955,  517,  ...,    0,    0,    0]], device='cuda:0'), 'text2_encoder_input_ids': tensor([[   2, 3139, 6213,  ...,    0,    0,    0],\n",
      "        [   2, 3121, 5330,  ...,    0,    0,    0],\n",
      "        [   2, 1423, 5330,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2, 4955, 3318,  ...,    0,    0,    0],\n",
      "        [   2, 1423, 5330,  ...,    0,    0,    0],\n",
      "        [   2, 4955,  517,  ...,    0,    0,    0]], device='cuda:0'), 'score': tensor([5, 4, 5, 2, 2, 2, 5, 2, 3, 5, 3, 1, 5, 5, 4, 0, 2, 5, 4, 0, 3, 1, 3, 2,\n",
      "        1, 1, 4, 3, 1, 0, 2, 5], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "device =torch.device(\"cuda:0\")\n",
    "for batch in valid_dataloader:\n",
    "    print(batch)\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    print('\\n')\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = sts_dev['sentence1'].tolist()\n",
    "sentence2 = sts_dev['sentence2'].tolist()\n",
    "\n",
    "sentence1_batch = tokenizer.batch_encode_plus(sentence1, return_tensors='pt', padding=True)\n",
    "sentence2_batch = tokenizer.batch_encode_plus(sentence2, return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[2, 3135, 5724, 7814, 3], [2, 2207, 5345, 6701, 3]], 'token_type_ids': [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus(['안녕하세요','반갑습니다'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3135, 5724, 7814, 3, 2207, 5345, 6701, 3]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('안녕하세요','반갑습니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Paper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    self,\n",
    "    eval_dataset: Optional[Dataset] = None,\n",
    "    ignore_keys: Optional[List[str]] = None,\n",
    "    metric_key_prefix: str = \"eval\",\n",
    "    eval_senteval_transfer: bool = False,\n",
    ") -> Dict[str, float]:\n",
    "\n",
    "    # SentEval prepare and batcher\n",
    "    def prepare(params, samples):\n",
    "        return\n",
    "\n",
    "    def batcher(params, batch):\n",
    "        sentences = [' '.join(s) for s in batch]\n",
    "        batch = self.tokenizer.batch_encode_plus(\n",
    "            sentences,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "        )\n",
    "        for k in batch:\n",
    "            batch[k] = batch[k].to(self.args.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**batch, output_hidden_states=True, return_dict=True, sent_emb=True)\n",
    "            pooler_output = outputs.pooler_output\n",
    "        return pooler_output.cpu()\n",
    "\n",
    "    # Set params for SentEval (fastmode)\n",
    "    params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
    "    params['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
    "                                        'tenacity': 3, 'epoch_size': 2}\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    tasks = ['STSBenchmark', 'SICKRelatedness']\n",
    "    if eval_senteval_transfer or self.args.eval_transfer:\n",
    "        tasks = ['STSBenchmark', 'SICKRelatedness', 'MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC']\n",
    "    self.model.eval()\n",
    "    results = se.eval(tasks)\n",
    "    \n",
    "    stsb_spearman = results['STSBenchmark']['dev']['spearman'][0]\n",
    "    sickr_spearman = results['SICKRelatedness']['dev']['spearman'][0]\n",
    "\n",
    "    metrics = {\"eval_stsb_spearman\": stsb_spearman, \"eval_sickr_spearman\": sickr_spearman, \"eval_avg_sts\": (stsb_spearman + sickr_spearman) / 2} \n",
    "    if eval_senteval_transfer or self.args.eval_transfer:\n",
    "        avg_transfer = 0\n",
    "        for task in ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC']:\n",
    "            avg_transfer += results[task]['devacc']\n",
    "            metrics['eval_{}'.format(task)] = results[task]['devacc']\n",
    "        avg_transfer /= 7\n",
    "        metrics['eval_avg_transfer'] = avg_transfer\n",
    "\n",
    "    self.log(metrics)\n",
    "    return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keonwoo_neo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "473a17fb9c005091cf4353665de455d9c74d3d37a8dc30122c5c3420cae1d5ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
